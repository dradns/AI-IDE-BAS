### 4.7. Especifica√ß√£o para Kafka Message Broker em Formato AsyncAPI

**Instru√ß√µes para descrever Kafka message broker**

**Idioma de execu√ß√£o:** Portugu√™s
**Formato do resultado:** Especifica√ß√£o AsyncAPI em formato YAML
**Local de salvamento:** Pasta do projeto com nome `{feature-name}_asyncapi.yaml`
**Padr√£o:** AsyncAPI 2.6.0 ou superior

#### 4.7.1. Conte√∫do
1. [Formato do arquivo de sa√≠da](#formato-do-arquivo-de-sa√≠da)
2. [Template de descri√ß√£o de arquitetura Kafka](#template-de-descri√ß√£o-de-arquitetura-kafka)
3. [M√©tricas de qualidade](#m√©tricas-de-qualidade)
4. [Regras de valida√ß√£o](#regras-de-valida√ß√£o)
5. [Metodologia de design](#metodologia-de-design)
6. [Exemplos de descri√ß√£o Kafka](#exemplos-de-descri√ß√£o-kafka)
7. [Crit√©rios de qualidade](#crit√©rios-de-qualidade)
8. [Checklist para agente de IA](#checklist-para-agente-de-ia)

---

#### 4.7.2. Formato do arquivo de sa√≠da

##### 4.7.2.1. Estrutura obrigat√≥ria de arquivo YAML AsyncAPI:

yaml
{feature-name}_asyncapi.yaml
asyncapi: '2.6.0'
info:
  title: '{Feature Name} Kafka Events API'
  version: '1.0.0'
  description: |
    Descri√ß√£o de eventos ass√≠ncronos para {feature-name} via Apache Kafka
    
    ## Prop√≥sito
    {Descri√ß√£o do prop√≥sito do sistema de eventos}
    
    ## Papel arquitetural
    {Papel na arquitetura geral do sistema}
    
  contact:
    name: 'Equipe de Desenvolvimento'
    email: 'dev-team@company.com'
  license:
    name: 'MIT'

servers:
  kafka-cluster:
    url: '{kafka-broker-urls}'
    protocol: kafka
    description: 'Cluster Kafka de produ√ß√£o'
    bindings:
      kafka:
        schemaRegistryUrl: 'http://schema-registry:8081'
        schemaRegistryVendor: 'confluent'
    security:
      - saslScram: []

defaultContentType: application/json

channels:
  'domain.entity.events':
    description: 'Eventos de ciclo de vida de {entidade}'
    bindings:
      kafka:
        topic: 'domain.entity.events'
        partitions: 12
        replicas: 3
        configs:
          retention.ms: 2592000000  # 30 dias
          cleanup.policy: 'delete'
          compression.type: 'snappy'
    publish:
      summary: 'Publica√ß√£o de eventos de {entidade}'
      operationId: 'publishEntityEvent'
      bindings:
        kafka:
          groupId: 'entity-producers'
          clientId: 'entity-service'
          acks: 'all'
          key:
            type: string
            description: 'ID da entidade para particionamento'
      message:
        $ref: '#/components/messages/EntityEvent'
    subscribe:
      summary: 'Assinatura de eventos de {entidade}'
      operationId: 'subscribeEntityEvent'
      bindings:
        kafka:
          groupId: 'entity-consumers'
          clientId: 'consumer-service'
      message:
        $ref: '#/components/messages/EntityEvent'

components:
  messages:
    EntityEvent:
      name: 'EntityEvent'
      title: 'Evento de Entidade'
      summary: 'Evento de mudan√ßa de estado da entidade'
      contentType: application/json
      headers:
        type: object
        properties:
          eventType:
            type: string
            enum: ['CREATED', 'UPDATED', 'DELETED']
          source:
            type: string
            description: 'Origem do evento'
          timestamp:
            type: string
            format: date-time
      payload:
        $ref: '#/components/schemas/EntityEventPayload'
      examples:
        - name: 'entityCreated'
          summary: 'Cria√ß√£o de entidade'
          headers:
            eventType: 'CREATED'
            source: 'entity-service'
            timestamp: '2024-01-15T10:30:00Z'
          payload:
            entityId: 'uuid-here'
            status: 'ACTIVE'
            createdAt: '2024-01-15T10:30:00Z'

  schemas:
    EntityEventPayload:
      type: object
      required:
        - entityId
        - status
        - createdAt
      properties:
        entityId:
          type: string
          format: uuid
          description: 'Identificador √∫nico da entidade'
        status:
          type: string
          enum: ['ACTIVE', 'INACTIVE', 'PENDING']
          description: 'Status da entidade'
        createdAt:
          type: string
          format: date-time
          description: 'Hora de cria√ß√£o do evento'
        metadata:
          type: object
          description: 'Dados adicionais'
          additionalProperties: true

  securitySchemes:
    saslScram:
      type: scramSha512
      description: 'Autentica√ß√£o SASL/SCRAM'


##### 4.7.2.2. Regras de nomenclatura de arquivos:
- `{feature-name}_asyncapi.yaml` - para funcionalidades principais
- `{domain}_events_asyncapi.yaml` - para solu√ß√µes de dom√≠nio
- `{system-name}_kafka_asyncapi.yaml` - para integra√ß√µes de sistema

**Exemplos:**
- `banking_transfer_asyncapi.yaml`
- `ecommerce_orders_asyncapi.yaml`
- `notification_events_asyncapi.yaml`

##### 4.7.2.3. Se√ß√µes AsyncAPI obrigat√≥rias:
1. **asyncapi**: vers√£o da especifica√ß√£o (2.6.0+)
2. **info**: metadados da API
3. **servers**: configura√ß√£o do cluster Kafka
4. **channels**: t√≥picos e sua configura√ß√£o
5. **components**: schemas de mensagens, esquemas de seguran√ßa
6. **x-kafka-config**: configura√ß√£o estendida do Kafka (opcional)

---

#### 4.7.3. Template de descri√ß√£o de arquitetura Kafka

##### 4.7.3.1. Estrutura obrigat√≥ria (9 blocos principais):

| ‚Ññ | Bloco | Descri√ß√£o | Obrigat√≥rio |
|---|------|----------|----------------|
| 1 | **Vis√£o geral** | Prop√≥sito do Kafka no sistema, papel na arquitetura | ‚úÖ Obrigat√≥rio |
| 2 | **T√≥picos e schemas** | Estrutura de t√≥picos, schemas de mensagens, particionamento | ‚úÖ Obrigat√≥rio |
| 3 | **Produtores** | Servi√ßos remetentes, estrat√©gias de envio | ‚úÖ Obrigat√≥rio |
| 4 | **Consumidores** | Servi√ßos receptores, grupos de consumidores | ‚úÖ Obrigat√≥rio |
| 5 | **Configura√ß√£o de cluster** | Configura√ß√µes de broker, replica√ß√£o, toler√¢ncia a falhas | ‚úÖ Obrigat√≥rio |
| 6 | **Schemas de dados** | Schemas Avro/JSON, Schema Registry, versionamento | ‚úÖ Obrigat√≥rio |
| 7 | **Seguran√ßa** | Autentica√ß√£o, autoriza√ß√£o, criptografia | üî∂ Recomendado |
| 8 | **Monitoramento e alertas** | M√©tricas, logging, SLA | üî∂ Recomendado |
| 9 | **Desempenho** | Throughput, lat√™ncia, otimiza√ß√µes | üî∂ Recomendado |

---

#### 4.7.4. M√©tricas de qualidade

##### 4.7.4.1. Indicadores alvo:
- **Completude de estrutura**: 6/6 blocos obrigat√≥rios = 100%
- **Cobertura de t√≥picos**: Descri√ß√£o de todos os t√≥picos principais do sistema
- **Schemas de dados**: 100% dos t√≥picos t√™m descri√ß√£o de schema
- **Grupos de consumidores**: Separa√ß√£o clara de responsabilidades
- **Toler√¢ncia a falhas**: M√≠nimo 2x replica√ß√£o para t√≥picos cr√≠ticos

##### 4.7.4.2. Sistema de pontua√ß√£o:
- **Pronto para produ√ß√£o**: 95-100% de conformidade + seguran√ßa + monitoramento
- **Excelente qualidade**: 85-94% de conformidade com m√©tricas
- **Boa qualidade**: 70-84% de conformidade com m√©tricas  
- **Precisa melhorar**: <70% de conformidade com m√©tricas

---

#### 4.7.5. Regras de valida√ß√£o

##### 4.7.5.1. Verifica√ß√µes autom√°ticas:

###### 4.7.5.1.1. Valida√ß√£o estrutural

‚úì Todos os 6 blocos obrigat√≥rios presentes
‚úì Cada t√≥pico tem descri√ß√£o de schema
‚úì Produtores e consumidores claramente identificados
‚úì Estrat√©gia de particionamento especificada


###### 4.7.5.1.2. Valida√ß√£o arquitetural

‚úì T√≥picos logicamente conectados a dom√≠nios do sistema
‚úì Schemas de dados correspondem a especifica√ß√µes de API
‚úì Grupos de consumidores n√£o se sobrep√µem em responsabilidade
‚úì Replica√ß√£o configurada para t√≥picos cr√≠ticos


###### 4.7.5.1.3. Valida√ß√£o de produ√ß√£o

‚úì Pol√≠ticas de reten√ß√£o especificadas para todos os t√≥picos
‚úì Estrat√©gia de tratamento de erros descrita
‚úì Monitoramento e alertas configurados
‚úì Procedimentos de recupera√ß√£o de desastres documentados


---

#### 4.7.6. Metodologia de design

##### 4.7.6.1. Passo 1: An√°lise de eventos de dom√≠nio
**Fontes para an√°lise:**
- User Stories e Use Cases
- Diagramas de sequ√™ncia
- Diagrama de arquitetura do sistema
- Especifica√ß√µes de API (para opera√ß√µes s√≠ncronas)

##### 4.7.6.2. Passo 2: Identifica√ß√£o de eventos
**Tipos de eventos:**
- **Eventos de Dom√≠nio**: mudan√ßas de estado de entidades de neg√≥cio
- **Eventos de Integra√ß√£o**: comunica√ß√£o entre servi√ßos
- **Eventos de Sistema**: eventos t√©cnicos (logs, m√©tricas)
- **Eventos de Comando**: comandos ass√≠ncronos

##### 4.7.6.3. Passo 3: Design de t√≥picos
**Princ√≠pios de nomenclatura:**

{domain}.{entity}.{event-type}
Exemplos:
- banking.transfer.created
- banking.transfer.completed
- ecommerce.order.placed
- notification.email.sent


##### 4.7.6.4. Passo 4: Defini√ß√£o de schema
**Formatos de schema:**
- **Avro**: tipagem estrita, evolu√ß√£o de schema
- **JSON Schema**: flexibilidade, simplicidade
- **Protobuf**: desempenho, compatibilidade

##### 4.7.6.5. Passo 5: Planejamento de parti√ß√µes
**Estrat√©gias de particionamento:**
- Por ID de usu√°rio (user-based)
- Por ID de entidade (entity-based)
- Por timestamps (time-based)
- Round-robin (distribui√ß√£o uniforme)

##### 4.7.6.6. Passo 6: Configura√ß√£o de consumidores
**Padr√µes de consumo:**
- **Single Consumer**: processamento em ordem
- **Consumer Group**: processamento paralelo
- **Multiple Groups**: l√≥gica de neg√≥cio diferente

---

#### 4.7.7. Checklist para agente de IA

##### 4.7.7.1. Verifica√ß√£o obrigat√≥ria:
- [ ] ‚úÖ Arquivo YAML AsyncAPI criado com nome correto
- [ ] ‚úÖ Vers√£o AsyncAPI especificada (2.6.0+)
- [ ] ‚úÖ Se√ß√£o info completamente preenchida
- [ ] ‚úÖ Servers cont√©m configura√ß√£o Kafka
- [ ] ‚úÖ Channels descrevem todos os t√≥picos
- [ ] ‚úÖ Cada channel tem opera√ß√µes publish/subscribe
- [ ] ‚úÖ Components cont√©m schemas de mensagens
- [ ] ‚úÖ Estrat√©gia de particionamento definida em bindings
- [ ] ‚úÖ Replica√ß√£o configurada em kafka bindings
- [ ] ‚úÖ Pol√≠ticas de reten√ß√£o descritas em configs
- [ ] ‚úÖ Schemas de dados v√°lidos (JSON Schema)
- [ ] ‚úÖ Grupos de consumidores especificados em bindings
- [ ] ‚úÖ Sintaxe YAML AsyncAPI correta

##### 4.7.7.2. Verifica√ß√£o de qualidade:
- [ ] üéØ T√≥picos logicamente conectados a dom√≠nios
- [ ] üéØ Schemas suportam evolu√ß√£o (compatibilidade retroativa)
- [ ] üéØ Tratamento de erros via DLQ descrito
- [ ] üéØ Processamento idempotente garantido
- [ ] üéØ Acknowledgements de produtor configurados corretamente
- [ ] üéØ Gest√£o de offset de consumidor definida

##### 4.7.7.3. Verifica√ß√£o de prontid√£o para produ√ß√£o:
- [ ] üöÄ Seguran√ßa: SASL/SSL, ACL configurados
- [ ] üöÄ Monitoramento: m√©tricas e alertas definidos
- [ ] üöÄ Desempenho: SLA e otimiza√ß√µes descritas
- [ ] üöÄ Procedimentos de backup e recupera√ß√£o de desastres
- [ ] üöÄ Schema Registry configurado
- [ ] üöÄ Monitoramento de lag de consumidor
- [ ] üöÄ Processamento de Dead Letter Queue
- [ ] üöÄ Planejamento de capacidade (parti√ß√µes, brokers)

##### 4.7.7.4. Verifica√ß√£o de integra√ß√£o:
- [ ] üîó Eventos correspondem a Use Cases
- [ ] üîó Schemas compat√≠veis com especifica√ß√µes de API
- [ ] üîó Servi√ßos produtores existem no diagrama de arquitetura
- [ ] üîó Grupos de consumidores n√£o conflitam em responsabilidade
- [ ] üîó Caracter√≠sticas de tempo realistas
- [ ] üîó Volumes de dados correspondem √† escala do sistema

**Objetivo**: Criar arquivos YAML com descri√ß√£o de arquitetura Kafka, prontos para implanta√ß√£o em produ√ß√£o com cobertura total de requisitos funcionais e n√£o-funcionais.
