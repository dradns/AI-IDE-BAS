### 4.7. Especificaci√≥n para Kafka Message Broker en formato AsyncAPI

**Instrucciones para describir el broker de mensajes Kafka**

**Idioma de la actuaci√≥n:** Espa√±ol
**Formato del resultado:** Especificaci√≥n AsyncAPI en formato YAML
**Ubicaci√≥n de guardado:** Carpeta del proyecto con nombre `{feature-name}_asyncapi.yaml`
**Est√°ndar:** AsyncAPI 2.6.0 o superior

#### 4.7.1. Contenido
1. [Formato de archivo de salida](#formato-de-archivo-de-salida)
2. [Plantilla de descripci√≥n de arquitectura Kafka](#plantilla-de-descripci√≥n-de-arquitectura-kafka)
3. [M√©tricas de calidad](#m√©tricas-de-calidad)
4. [Reglas de validaci√≥n](#reglas-de-validaci√≥n)
5. [Metodolog√≠a de dise√±o](#metodolog√≠a-de-dise√±o)
6. [Ejemplos de descripci√≥n Kafka](#ejemplos-de-descripci√≥n-kafka)
7. [Criterios de calidad](#criterios-de-calidad)
8. [Lista de verificaci√≥n para agente IA](#lista-de-verificaci√≥n-para-agente-ia)

---

#### 4.7.2. Formato de archivo de salida

##### 4.7.2.1. Estructura obligatoria de archivo YAML AsyncAPI:

yaml
# {feature-name}_asyncapi.yaml
asyncapi: '2.6.0'
info:
  title: '{Feature Name} Kafka Events API'
  version: '1.0.0'
  description: |
    Descripci√≥n de eventos asincr√≥nicos para {feature-name} mediante Apache Kafka
    
    ## Prop√≥sito
    {Descripci√≥n del prop√≥sito del sistema de eventos}
    
    ## Rol arquitect√≥nico
    {Rol en la arquitectura general del sistema}
    
  contact:
    name: 'Equipo de Desarrollo'
    email: 'dev-team@company.com'
  license:
    name: 'MIT'

servers:
  kafka-cluster:
    url: '{kafka-broker-urls}'
    protocol: kafka
    description: 'Cl√∫ster Kafka de producci√≥n'
    bindings:
      kafka:
        schemaRegistryUrl: 'http://schema-registry:8081'
        schemaRegistryVendor: 'confluent'
    security:
      - saslScram: []

defaultContentType: application/json

channels:
  'domain.entity.events':
    description: 'Eventos del ciclo de vida de {entity}'
    bindings:
      kafka:
        topic: 'domain.entity.events'
        partitions: 12
        replicas: 3
        configs:
          retention.ms: 2592000000  # 30 d√≠as
          cleanup.policy: 'delete'
          compression.type: 'snappy'
    publish:
      summary: 'Publicaci√≥n de eventos de {entity}'
      operationId: 'publishEntityEvent'
      bindings:
        kafka:
          groupId: 'entity-producers'
          clientId: 'entity-service'
          acks: 'all'
          key:
            type: string
            description: 'ID de entidad para particionamiento'
      message:
        $ref: '#/components/messages/EntityEvent'
    subscribe:
      summary: 'Suscripci√≥n a eventos de {entity}'
      operationId: 'subscribeEntityEvent'
      bindings:
        kafka:
          groupId: 'entity-consumers'
          clientId: 'consumer-service'
      message:
        $ref: '#/components/messages/EntityEvent'

components:
  messages:
    EntityEvent:
      name: 'EntityEvent'
      title: 'Evento de Entidad'
      summary: 'Evento de cambio de estado de entidad'
      contentType: application/json
      headers:
        type: object
        properties:
          eventType:
            type: string
            enum: ['CREATED', 'UPDATED', 'DELETED']
          source:
            type: string
            description: 'Fuente del evento'
          timestamp:
            type: string
            format: date-time
      payload:
        $ref: '#/components/schemas/EntityEventPayload'
      examples:
        - name: 'entityCreated'
          summary: 'Creaci√≥n de entidad'
          headers:
            eventType: 'CREATED'
            source: 'entity-service'
            timestamp: '2024-01-15T10:30:00Z'
          payload:
            entityId: 'uuid-here'
            status: 'ACTIVE'
            createdAt: '2024-01-15T10:30:00Z'

  schemas:
    EntityEventPayload:
      type: object
      required:
        - entityId
        - status
        - createdAt
      properties:
        entityId:
          type: string
          format: uuid
          description: 'Identificador √∫nico de entidad'
        status:
          type: string
          enum: ['ACTIVE', 'INACTIVE', 'PENDING']
          description: 'Estado de la entidad'
        createdAt:
          type: string
          format: date-time
          description: 'Tiempo de creaci√≥n del evento'
        metadata:
          type: object
          description: 'Datos adicionales'
          additionalProperties: true
      example:
        entityId: 'f47ac10b-58cc-4372-a567-0e02b2c3d479'
        status: 'ACTIVE'
        createdAt: '2024-01-15T10:30:00Z'
        metadata:
          source: 'web-app'
          userId: 'user-123'

  securitySchemes:
    saslScram:
      type: scramSha512
      description: 'Autenticaci√≥n SASL/SCRAM'

  parameters:
    EntityId:
      description: 'Identificador de entidad'
      schema:
        type: string
        format: uuid

# Configuraci√≥n adicional de Kafka (en secci√≥n x-kafka-config)
x-kafka-config:
  cluster:
    brokers: 3
    replication:
      default: 2
      critical_topics: 3
    resources:
      broker_memory: '4Gi'
      broker_cpu: '2'
      broker_storage: '100Gi'
  
  producers:
    default_config:
      acks: 'all'
      retries: 10
      batch.size: 100000
      linger.ms: 5
      enable.idempotence: true
      compression.type: 'snappy'
    
  consumers:
    default_config:
      auto.commit.enable: false
      max.poll.records: 500
      session.timeout.ms: 30000
      fetch.min.bytes: 1
      
  monitoring:
    metrics:
      - 'kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec'
      - 'kafka.consumer:type=consumer-fetch-manager-metrics'
      - 'kafka.producer:type=producer-metrics'
    alerts:
      - name: 'high_consumer_lag'
        condition: 'consumer_lag > 10000'
        severity: 'critical'
      - name: 'broker_down'
        condition: 'broker_availability < 100%'
        severity: 'critical'
        
  security:
    authentication:
      protocol: 'SASL_SSL'
      mechanism: 'SCRAM-SHA-512'
    acls:
      - principal: 'User:entity-service'
        operations: ['Write', 'Describe']
        resources: ['Topic:domain.entity.events']
      - principal: 'User:consumer-service'
        operations: ['Read', 'Describe']
        resources: ['Topic:domain.entity.events', 'Group:entity-consumers']


##### 4.7.2.2. Reglas de nomenclatura de archivos:
- `{feature-name}_asyncapi.yaml` - para caracter√≠sticas principales
- `{domain}_events_asyncapi.yaml` - para soluciones de dominio
- `{system-name}_kafka_asyncapi.yaml` - para integraciones de sistemas

**Ejemplos:**
- `banking_transfer_asyncapi.yaml`
- `ecommerce_orders_asyncapi.yaml`
- `notification_events_asyncapi.yaml`

##### 4.7.2.3. Secciones obligatorias de AsyncAPI:
1. **asyncapi**: versi√≥n de especificaci√≥n (2.6.0+)
2. **info**: metadatos de API
3. **servers**: configuraci√≥n de cl√∫ster Kafka
4. **channels**: t√≥picos y su configuraci√≥n
5. **components**: esquemas de mensajes, esquemas de seguridad
6. **x-kafka-config**: configuraci√≥n extendida de Kafka (opcional)

---

#### 4.7.3. Plantilla de descripci√≥n de arquitectura Kafka

##### 4.7.3.1. Estructura obligatoria (9 bloques principales):

| ‚Ññ | Bloque | Descripci√≥n | Obligatoriedad |
|---|------|----------|----------------|
| 1 | **Descripci√≥n general** | Prop√≥sito de Kafka en el sistema, rol en arquitectura | ‚úÖ Obligatorio |
| 2 | **T√≥picos y esquemas** | Estructura de t√≥picos, esquemas de mensajes, particionamiento | ‚úÖ Obligatorio |
| 3 | **Productores** | Servicios emisores, estrategias de env√≠o | ‚úÖ Obligatorio |
| 4 | **Consumidores** | Servicios receptores, grupos de consumidores | ‚úÖ Obligatorio |
| 5 | **Configuraci√≥n de cl√∫ster** | Configuraciones de brokers, replicaci√≥n, tolerancia a fallos | ‚úÖ Obligatorio |
| 6 | **Esquemas de datos** | Esquemas Avro/JSON, Schema Registry, versionado | ‚úÖ Obligatorio |
| 7 | **Seguridad** | Autenticaci√≥n, autorizaci√≥n, encriptaci√≥n | üî∂ Recomendado |
| 8 | **Monitoreo y alertas** | M√©tricas, logging, SLA | üî∂ Recomendado |
| 9 | **Rendimiento** | Throughput, latencia, optimizaciones | üî∂ Recomendado |

---

#### 4.7.4. M√©tricas de calidad

##### 4.7.4.1. Indicadores objetivo:
- **Completitud estructural**: 6/6 bloques obligatorios = 100%
- **Cobertura de t√≥picos**: Descripci√≥n de todos los t√≥picos principales del sistema
- **Esquemas de datos**: 100% t√≥picos tienen descripci√≥n de esquema
- **Grupos de consumidores**: Separaci√≥n clara de responsabilidades
- **Tolerancia a fallos**: M√≠nimo 2x replicaci√≥n para t√≥picos cr√≠ticos

##### 4.7.4.2. Sistema de evaluaci√≥n:
- **Listo para producci√≥n**: 95-100% cumplimiento + seguridad + monitoreo
- **Calidad excelente**: 85-94% cumplimiento de m√©tricas
- **Buena calidad**: 70-84% cumplimiento de m√©tricas  
- **Requiere mejora**: <70% cumplimiento de m√©tricas

---

#### 4.7.5. Reglas de validaci√≥n

##### 4.7.5.1. Comprobaciones autom√°ticas:

###### 4.7.5.1.1. Validaci√≥n estructural

‚úì Los 6 bloques obligatorios presentes
‚úì Cada t√≥pico tiene descripci√≥n de esquema
‚úì Productores y consumidores claramente identificados
‚úì Estrategia de particionamiento especificada


###### 4.7.5.1.2. Validaci√≥n arquitect√≥nica

‚úì T√≥picos conectados l√≥gicamente con dominios del sistema
‚úì Esquemas de datos corresponden a especificaciones API
‚úì Grupos de consumidores no se superponen en responsabilidad
‚úì Replicaci√≥n configurada para t√≥picos cr√≠ticos


###### 4.7.5.1.3. Validaci√≥n de producci√≥n

‚úì Pol√≠ticas de retenci√≥n especificadas para todos los t√≥picos
‚úì Estrategia de manejo de errores descrita
‚úì Monitoreo y alertas configurados
‚úì Procedimientos de recuperaci√≥n ante desastres documentados


---

#### 4.7.6. Metodolog√≠a de dise√±o

##### 4.7.6.1. Paso 1: An√°lisis de eventos de dominio
**Fuentes para an√°lisis:**
- User Stories y Use Cases
- Diagramas de secuencia
- Diagrama de arquitectura del sistema
- Especificaciones API (para operaciones s√≠ncronas)

##### 4.7.6.2. Paso 2: Identificaci√≥n de eventos
**Tipos de eventos:**
- **Eventos de Dominio**: cambios de estado de entidades de negocio
- **Eventos de Integraci√≥n**: comunicaci√≥n entre servicios
- **Eventos de Sistema**: eventos t√©cnicos (logs, m√©tricas)
- **Eventos de Comando**: comandos asincr√≥nicos

##### 4.7.6.3. Paso 3: Dise√±o de t√≥picos
**Principios de nomenclatura:**

{domain}.{entity}.{event-type}
Ejemplos:
- banking.transfer.created
- banking.transfer.completed
- ecommerce.order.placed
- notification.email.sent


##### 4.7.6.4. Paso 4: Definici√≥n de esquemas
**Formatos de esquemas:**
- **Avro**: tipado estricto, evoluci√≥n de esquemas
- **JSON Schema**: flexibilidad, simplicidad
- **Protobuf**: rendimiento, compatibilidad

##### 4.7.6.5. Paso 5: Planificaci√≥n de particiones
**Estrategias de particionamiento:**
- Por ID de usuario (basado en usuario)
- Por ID de entidad (basado en entidad)
- Por marcas de tiempo (basado en tiempo)
- Round-robin (distribuci√≥n uniforme)

##### 4.7.6.6. Paso 6: Configuraci√≥n de consumidores
**Patrones de consumo:**
- **Consumidor √önico**: procesamiento en orden
- **Grupo de Consumidores**: procesamiento paralelo
- **M√∫ltiples Grupos**: l√≥gica de negocio diferente

---

#### 4.7.7. Ejemplos de descripci√≥n Kafka

##### 4.7.7.1. Ejemplo 1: Sistema de transferencias bancarias

###### 4.7.7.1.1. Descripci√≥n general
**Prop√≥sito:** Procesamiento asincr√≥nico de transferencias bancarias con garant√≠as de entrega y auditor√≠a de operaciones.
**Rol en arquitectura:** Bus de eventos central entre microservicios Banking, Notification, Audit, Fraud Detection.

###### 4.7.7.1.2. T√≥picos y esquemas

**2.1. T√≥pico: `banking.transfer.events`**
yaml
Prop√≥sito: Eventos del ciclo de vida de transferencias
Particiones: 12 (por account_id % 12)
Factor de Replicaci√≥n: 3
Retenci√≥n: 30 d√≠as
Pol√≠tica de Limpieza: delete


**Esquema de mensaje (Avro):**
json
{
  "type": "record",
  "name": "TransferEvent",
  "namespace": "com.bank.events",
  "fields": [
    {"name": "transferId", "type": "string"},
    {"name": "fromAccountId", "type": "string"},
    {"name": "toAccountId", "type": "string"},
    {"name": "amount", "type": {"type": "fixed", "name": "Decimal", "size": 16}},
    {"name": "currency", "type": "string"},
    {"name": "status", "type": {"type": "enum", "symbols": ["PENDING", "PROCESSING", "COMPLETED", "FAILED"]}},
    {"name": "timestamp", "type": {"type": "long", "logicalType": "timestamp-millis"}},
    {"name": "userId", "type": "string"},
    {"name": "comment", "type": ["null", "string"], "default": null}
  ]
}


**2.2. T√≥pico: `banking.notifications.requests`**
yaml
Prop√≥sito: Solicitudes de env√≠o de notificaciones
Particiones: 6 (por user_id % 6)
Factor de Replicaci√≥n: 2
Retenci√≥n: 7 d√≠as


**2.3. T√≥pico: `banking.audit.log`**
yaml
Prop√≥sito: Auditor√≠a de todas las operaciones para cumplimiento
Particiones: 1 (orden estricto)
Factor de Replicaci√≥n: 3
Retenci√≥n: 7 a√±os (requisitos de cumplimiento)
Pol√≠tica de Limpieza: compact


###### 4.7.7.1.3. Productores

**3.1. Servicio de Transferencia (Productor principal)**
yaml
Servicio: transfer-service
T√≥picos: banking.transfer.events
Estrategia: 
  - Idempotencia: habilitada
  - Acks: all (garant√≠a de escritura en todas las r√©plicas)
  - Reintentos: 10
  - Tama√±o de Lote: 100KB
  - Tiempo de Espera: 5ms
Manejo de errores:
  - Reintento con exponential backoff
  - Cola de Mensajes Muertos: banking.transfer.dlq


**Ejemplo de c√≥digo:**
java
@Service
public class TransferEventProducer {
    
    @Value("${kafka.topic.transfer-events}")
    private String transferEventsTopic;
    
    public void publishTransferEvent(TransferEvent event) {
        kafkaTemplate.send(transferEventsTopic, event.getFromAccountId(), event)
            .addCallback(
                result -> log.info("Event sent: {}", event.getTransferId()),
                failure -> log.error("Failed to send event", failure)
            );
    }
}


**3.2. Servicio de Notificaciones**
yaml
Servicio: notification-service  
T√≥picos: banking.notifications.requests
Estrategia: Fire-and-forget (acks=1)


###### 4.7.7.1.4. Consumidores

**4.1. Servicio de Detecci√≥n de Fraude**
yaml
Grupo: fraud-detection-group
T√≥picos: banking.transfer.events
Estrategia:
  - Auto Commit: false (confirmaci√≥n manual)
  - Registros M√°ximos por Poll: 50
  - Tiempo de Espera de Sesi√≥n: 30s
  - Asignaci√≥n de Particiones: cooperative-sticky
L√≥gica:
  - An√°lisis de fraude
  - Publicaci√≥n de resultado en fraud.detection.results


**4.2. Servicio de Auditor√≠a**
yaml
Grupo: audit-group
T√≥picos: 
  - banking.transfer.events
  - banking.notifications.requests
Estrategia:
  - Offset m√°s temprano (procesamiento de todos los eventos)
  - Procesamiento por lotes (100 registros a la vez)
  - Procesamiento idempotente


**4.3. Consumidor de Notificaciones**
yaml
Grupo: notification-consumers
T√≥picos: banking.notifications.requests
Paralelismo: 3 instancias
Pol√≠tica de Reintento:
  - Reintentos m√°ximos: 5
  - Backoff: exponencial (1s, 2s, 4s, 8s, 16s)
  - DLQ: banking.notifications.dlq


###### 4.7.7.1.5. Configuraci√≥n de cl√∫ster

**5.1. Brokers**
yaml
N√∫mero de brokers: 3
Ubicaci√≥n: 3 AZ diferentes
Configuraci√≥n:
  - log.retention.hours: 168 (7 d√≠as por defecto)
  - log.segment.bytes: 1GB
  - num.network.threads: 8
  - num.io.threads: 8
  - socket.send.buffer.bytes: 102400
  - socket.receive.buffer.bytes: 102400


**5.2. Zookeeper**
yaml
Nodos: 3 (qu√≥rum)
Configuraci√≥n:
  - tickTime: 2000
  - initLimit: 10  
  - syncLimit: 5
  - maxClientCnxns: 60


**5.3. Replicaci√≥n**
yaml
T√≥picos cr√≠ticos (transfers, audit): RF=3, min.insync.replicas=2
T√≥picos regulares (notifications): RF=2, min.insync.replicas=1
T√≥picos de prueba: RF=1


###### 4.7.7.1.6. Esquemas de datos

**6.1. Schema Registry**
yaml
URL: http://schema-registry:8081
Compatibilidad: BACKWARD
Versionado: autom√°tico
Subjects:
  - banking.transfer.events-value (v1, v2)
  - banking.notifications.requests-value (v1)
  - banking.audit.log-value (v1)


**6.2. Evoluci√≥n de esquema**
json
// v1 -> v2: agregando campo metadata
{
  "type": "record",
  "name": "TransferEvent",
  "fields": [
    // ... campos existentes ...
    {"name": "metadata", "type": ["null", "string"], "default": null}
  ]
}


###### 4.7.7.1.7. Seguridad

**7.1. Autenticaci√≥n**
yaml
Protocolo: SASL_SSL
Mecanismo: SCRAM-SHA-512
Usuarios:
  - transfer-service: acceso RW a banking.transfer.*
  - notification-service: acceso RW a banking.notifications.*
  - audit-service: acceso R a todos los t√≥picos
  - fraud-detection: acceso R a banking.transfer.events


**7.2. Autorizaci√≥n (ACL)**
bash
# Servicio de Transferencia
kafka-acls --add --allow-principal User:transfer-service \
  --operation Write --topic banking.transfer.events

# Detecci√≥n de Fraude
kafka-acls --add --allow-principal User:fraud-detection \
  --operation Read --topic banking.transfer.events \
  --group fraud-detection-group


**7.3. Encriptaci√≥n**
yaml
En tr√°nsito: TLS 1.3
En reposo: encriptaci√≥n de disco LUKS
Schema Registry: mTLS + autenticaci√≥n b√°sica


###### 4.7.7.1.8. Monitoreo y alertas

**8.1. M√©tricas clave**
yaml
M√©tricas de Broker:
  - kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
  - kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec
  - kafka.server:type=ReplicaManager,name=LeaderCount

Lag de Consumidor:
  - kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*

M√©tricas de Productor:
  - kafka.producer:type=producer-metrics,client-id=*


**8.2. Alertas**
yaml
Cr√≠ticas:
  - Lag de Consumidor > 10000 mensajes
  - Broker no disponible > 1 minuto
  - Uso de disco > 85%

Advertencias:
  - Errores de Productor > 1%
  - Lag de Replicaci√≥n > 5 segundos
  - Rebalanceo de grupo de consumidores


**8.3. Dashboards**
yaml
Paneles de Grafana:
  - Vista General del Cl√∫ster Kafka
  - Rendimiento de T√≥picos
  - Estado de Grupos de Consumidores
  - Rendimiento de Productores
  - Tasas de Error


###### 4.7.7.1.9. Rendimiento

**9.1. Caracter√≠sticas de throughput**
yaml
Indicadores objetivo:
  - Transferencias: 10,000 msg/seg
  - Notificaciones: 5,000 msg/seg
  - Auditor√≠a: 15,000 msg/seg

Latencia (p99):
  - Productor: < 50ms
  - Consumidor: < 100ms
  - Extremo a extremo: < 200ms


**9.2. Optimizaciones**
yaml
Productor:
  - Tama√±o de lote: 100KB
  - Tiempo de espera: 5ms
  - Compresi√≥n: snappy

Consumidor:
  - Tama√±o de fetch: 1MB
  - Registros m√°ximos por poll: 500
  - Procesamiento paralelo

Broker:
  - Segmento de log: 1GB
  - Flush de log: as√≠ncrono
  - Cache de p√°gina: 70% RAM


---

##### 4.7.7.2. Ejemplo 2: Plataforma E-commerce

###### 4.7.7.2.1. Descripci√≥n general
**Prop√≥sito:** Arquitectura dirigida por eventos para e-commerce con procesamiento de pedidos, inventario y notificaciones.
**Rol en arquitectura:** Bus de eventos principal entre Order Service, Inventory Service, Payment Service, Notification Service.

###### 4.7.7.2.2. T√≥picos y esquemas

**2.1. T√≥pico: `ecommerce.orders.events`**
yaml
Prop√≥sito: Eventos del ciclo de vida de pedidos
Particiones: 8 (por hash de order_id)
Factor de Replicaci√≥n: 2
Retenci√≥n: 14 d√≠as


**Esquema (JSON Schema):**
json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "orderId": {"type": "string", "format": "uuid"},
    "customerId": {"type": "string", "format": "uuid"},
    "status": {"enum": ["PLACED", "CONFIRMED", "SHIPPED", "DELIVERED", "CANCELLED"]},
    "items": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "productId": {"type": "string"},
          "quantity": {"type": "integer", "minimum": 1},
          "price": {"type": "number", "minimum": 0}
        }
      }
    },
    "totalAmount": {"type": "number", "minimum": 0},
    "timestamp": {"type": "string", "format": "date-time"}
  },
  "required": ["orderId", "customerId", "status", "items", "totalAmount", "timestamp"]
}


**2.2. T√≥pico: `ecommerce.inventory.updates`**
yaml
Prop√≥sito: Actualizaciones de stock de productos
Particiones: 4 (por hash de product_id)
Factor de Replicaci√≥n: 2
Retenci√≥n: 7 d√≠as
Pol√≠tica de Limpieza: compact (estado m√°s reciente)


**2.3. T√≥pico: `ecommerce.payments.events`**
yaml
Prop√≥sito: Eventos de pagos
Particiones: 6
Factor de Replicaci√≥n: 3 (datos cr√≠ticos)
Retenci√≥n: 365 d√≠as (cumplimiento)


###### 4.7.7.2.3. Productores

**3.1. Order Service**
yaml
T√≥picos: ecommerce.orders.events
Configuraci√≥n:
  - acks: all
  - enable.idempotence: true
  - retries: Integer.MAX_VALUE
  - max.in.flight.requests.per.connection: 5

Patr√≥n Outbox:
  - Escritura transaccional en BD + Kafka
  - Garant√≠as de consistencia eventual


**3.2. Inventory Service**
yaml
T√≥picos: ecommerce.inventory.updates
Estrategia: T√≥pico compactado para estado actual


###### 4.7.7.2.4. Consumidores

**4.1. Payment Service**
yaml
Grupo: payment-processors
T√≥picos: ecommerce.orders.events
Filtro: status = "PLACED"
L√≥gica: Iniciaci√≥n de pago
Resultado: Publicaci√≥n en ecommerce.payments.events


**4.2. Inventory Service**  
yaml
Grupo: inventory-updaters
T√≥picos: ecommerce.orders.events
L√≥gica: Reserva/liberaci√≥n de productos
Idempotencia: Por order_id + item_id


**4.3. Notification Service**
yaml
Grupo: notification-senders
T√≥picos: 
  - ecommerce.orders.events
  - ecommerce.payments.events
Paralelismo: 5 consumidores
Reintento: 3 intentos con backoff


###### 4.7.7.2.5. Configuraci√≥n de cl√∫ster

**5.1. Despliegue**
yaml
Entorno: Kubernetes
Brokers: 3 pods
Recursos:
  - CPU: 2 n√∫cleos
  - Memoria: 4GB
  - Almacenamiento: 100GB SSD por broker


**5.2. Configuraciones de rendimiento**
yaml
log.retention.bytes: 10GB por partici√≥n
log.segment.bytes: 512MB
compression.type: snappy
num.replica.fetchers: 4


###### 4.7.7.2.6. Monitoreo

**6.1. M√©tricas de negocio**
yaml
- Pedidos procesados por minuto
- Tasa de √©xito de pagos
- Retraso de sincronizaci√≥n de inventario
- Tasa de entrega de notificaciones a clientes


**6.2. M√©tricas t√©cnicas**
yaml
- Lag de consumidor por t√≥pico
- Throughput de productor
- Tasas de error por servicio
- Distribuci√≥n de particiones


---

#### 4.7.8. Criterios de calidad para IA

##### 4.7.8.1. Madurez arquitect√≥nica
- **Obligatorio**: Todos los 6 bloques principales completados
- **Producci√≥n**: Bloques de seguridad, monitoreo, rendimiento agregados
- **Empresa**: Recuperaci√≥n ante desastres, cumplimiento, gobierno agregados

##### 4.7.8.2. Detallado t√©cnico
- **T√≥picos**: Esquema de particionamiento claro y pol√≠ticas de retenci√≥n
- **Esquemas**: Esquemas Avro/JSON v√°lidos con ejemplos
- **Configuraci√≥n**: Configuraciones realistas para carga objetivo
- **Seguridad**: ACL, autenticaci√≥n, encriptaci√≥n

##### 4.7.8.3. Preparaci√≥n operacional
- **Monitoreo**: M√©tricas clave y alertas definidas
- **Manejo de errores**: DLQ, pol√≠ticas de reintento, circuit breakers
- **Rendimiento**: SLA, requisitos de throughput y latencia
- **Recuperaci√≥n ante Desastres**: Procedimientos de backup, restore, failover

##### 4.7.8.4. Integraci√≥n con sistema
- **Eventos de Dominio**: Corresponden con l√≥gica de negocio de Use Cases
- **Integraci√≥n API**: Complementan arquitectura REST API
- **Flujo de Datos**: Consistentes con diagramas de secuencia
- **Servicios**: Corresponden con arquitectura de componentes

---

#### 4.7.9. Lista de verificaci√≥n para agente IA

##### 4.7.9.1. Verificaci√≥n obligatoria:
- [ ] ‚úÖ Archivo YAML AsyncAPI creado con nombre correcto
- [ ] ‚úÖ Versi√≥n AsyncAPI especificada (2.6.0+)
- [ ] ‚úÖ Secci√≥n info completamente completada
- [ ] ‚úÖ Servers contiene configuraci√≥n Kafka
- [ ] ‚úÖ Channels describe todos los t√≥picos
- [ ] ‚úÖ Cada channel tiene operaciones publish/subscribe
- [ ] ‚úÖ Components contiene esquemas de mensajes
- [ ] ‚úÖ Estrategia de particionamiento definida en bindings
- [ ] ‚úÖ Replicaci√≥n configurada en kafka bindings
- [ ] ‚úÖ Pol√≠ticas de retenci√≥n descritas en configs
- [ ] ‚úÖ Esquemas de datos v√°lidos (JSON Schema)
- [ ] ‚úÖ Grupos de consumidores especificados en bindings
- [ ] ‚úÖ Sintaxis YAML AsyncAPI correcta

##### 4.7.9.2. Verificaci√≥n de calidad:
- [ ] üéØ T√≥picos conectados l√≥gicamente con dominios
- [ ] üéØ Esquemas soportan evoluci√≥n (compatibilidad hacia atr√°s)
- [ ] üéØ Manejo de errores mediante DLQ descrito
- [ ] üéØ Procesamiento idempotente asegurado
- [ ] üéØ Acuses de recibo de productor configurados correctamente
- [ ] üéØ Gesti√≥n de offset de consumidor definida

##### 4.7.9.3. Verificaci√≥n listo para producci√≥n:
- [ ] üöÄ Seguridad: SASL/SSL, ACL configurados
- [ ] üöÄ Monitoreo: m√©tricas y alertas definidas
- [ ] üöÄ Rendimiento: SLA y optimizaciones descritas
- [ ] üöÄ Procedimientos de backup y recuperaci√≥n ante desastres
- [ ] üöÄ Schema Registry configurado
- [ ] üöÄ Monitoreo de lag de consumidor
- [ ] üöÄ Procesamiento de Dead Letter Queue
- [ ] üöÄ Planificaci√≥n de capacidad (particiones, brokers)

##### 4.7.9.4. Verificaci√≥n de integraci√≥n:
- [ ] üîó Eventos corresponden con Use Cases
- [ ] üîó Esquemas compatibles con especificaciones API
- [ ] üîó Servicios productores existen en diagrama de arquitectura
- [ ] üîó Grupos de consumidores no conflictivos en responsabilidad
- [ ] üîó Caracter√≠sticas de tiempo realistas
- [ ] üîó Vol√∫menes de datos corresponden con escala del sistema

**Objetivo**: Crear archivos YAML con descripci√≥n de arquitectura Kafka, listos para despliegue en producci√≥n con cobertura completa de requisitos funcionales y no funcionales.

##### 4.7.9.5. Verificaci√≥n final YAML AsyncAPI:
- [ ] üìÑ Archivo guardado con extensi√≥n .yaml
- [ ] üìÑ Nombre de archivo sigue convenci√≥n de nomenclatura
- [ ] üìÑ Estructura AsyncAPI corresponde a especificaci√≥n
- [ ] üìÑ Todos los valores de cadena entre comillas
- [ ] üìÑ Indentaci√≥n realizada con espacios (no tabs)
- [ ] üìÑ JSON Schema correctamente definidos en components
- [ ] üìÑ Kafka bindings configurados para channels
- [ ] üìÑ Esquemas de seguridad definidos cuando sea necesario
- [ ] üìÑ Ejemplos incluidos para cada tipo de mensaje

---

#### 4.7.10. Recomendaciones adicionales

##### 4.7.10.1. Estilo de documentaci√≥n:
- **Estructura**: Use YAML para configuraciones
- **Especificidad**: Especifique n√∫meros exactos de particiones, retenci√≥n, throughput
- **Ejemplos**: Incluya ejemplos reales de esquemas Avro/JSON Schema
- **Visualizaci√≥n**: Diagramas ASCII para topolog√≠a

##### 4.7.10.2. Aspectos de producci√≥n:
- **Nomenclatura**: Siga convenciones {domain}.{entity}.{event}
- **Particionamiento**: Justifique elecci√≥n de clave de particionamiento
- **Retenci√≥n**: Considere cumplimiento y costos de almacenamiento
- **Versionado**: Planifique evoluci√≥n de esquemas por adelantado

##### 4.7.10.3. Integraci√≥n con DevOps:
- **Infraestructura como C√≥digo**: Configuraciones Terraform/Helm
- **CI/CD**: Validaci√≥n de esquemas en pipeline
- **Monitoreo**: M√©tricas Prometheus/Grafana
- **Alertas**: Integraciones PagerDuty/Slack

##### 4.7.10.4. Recuperaci√≥n ante Desastres:
- **Backup**: MirrorMaker 2.0 para replicaci√≥n
- **Recuperaci√≥n**: Requisitos RTO/RPO
- **Pruebas**: Pr√°cticas de ingenier√≠a del caos
- **Documentaci√≥n**: Runbooks para equipo de operaciones


