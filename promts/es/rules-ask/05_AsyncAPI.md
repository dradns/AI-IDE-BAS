### 4.7. EspecificaciÃ³n para Kafka Message Broker en formato AsyncAPI

**Instrucciones para describir el broker de mensajes Kafka**

**Idioma de la actuaciÃ³n:** EspaÃ±ol
**Formato del resultado:** EspecificaciÃ³n AsyncAPI en formato YAML
**UbicaciÃ³n de guardado:** Carpeta del proyecto con nombre `{feature-name}_asyncapi.yaml`
**EstÃ¡ndar:** AsyncAPI 2.6.0 o superior

#### 4.7.1. Contenido
1. [Formato de archivo de salida](#formato-de-archivo-de-salida)
2. [Plantilla de descripciÃ³n de arquitectura Kafka](#plantilla-de-descripciÃ³n-de-arquitectura-kafka)
3. [MÃ©tricas de calidad](#mÃ©tricas-de-calidad)
4. [Reglas de validaciÃ³n](#reglas-de-validaciÃ³n)
5. [MetodologÃ­a de diseÃ±o](#metodologÃ­a-de-diseÃ±o)
6. [Ejemplos de descripciÃ³n Kafka](#ejemplos-de-descripciÃ³n-kafka)
7. [Criterios de calidad](#criterios-de-calidad)
8. [Lista de verificaciÃ³n para agente IA](#lista-de-verificaciÃ³n-para-agente-ia)

---

#### 4.7.2. Formato de archivo de salida

##### 4.7.2.1. Estructura obligatoria de archivo YAML AsyncAPI:

yaml
# {feature-name}_asyncapi.yaml
asyncapi: '2.6.0'
info:
  title: '{Feature Name} Kafka Events API'
  version: '1.0.0'
  description: |
    DescripciÃ³n de eventos asincrÃ³nicos para {feature-name} mediante Apache Kafka
    
    ## PropÃ³sito
    {DescripciÃ³n del propÃ³sito del sistema de eventos}
    
    ## Rol arquitectÃ³nico
    {Rol en la arquitectura general del sistema}
    
  contact:
    name: 'Equipo de Desarrollo'
    email: 'dev-team@company.com'
  license:
    name: 'MIT'

servers:
  kafka-cluster:
    url: '{kafka-broker-urls}'
    protocol: kafka
    description: 'ClÃºster Kafka de producciÃ³n'
    bindings:
      kafka:
        schemaRegistryUrl: 'http://schema-registry:8081'
        schemaRegistryVendor: 'confluent'
    security:
      - saslScram: []

defaultContentType: application/json

channels:
  'domain.entity.events':
    description: 'Eventos del ciclo de vida de {entity}'
    bindings:
      kafka:
        topic: 'domain.entity.events'
        partitions: 12
        replicas: 3
        configs:
          retention.ms: 2592000000  # 30 dÃ­as
          cleanup.policy: 'delete'
          compression.type: 'snappy'
    publish:
      summary: 'PublicaciÃ³n de eventos de {entity}'
      operationId: 'publishEntityEvent'
      bindings:
        kafka:
          groupId: 'entity-producers'
          clientId: 'entity-service'
          acks: 'all'
          key:
            type: string
            description: 'ID de entidad para particionamiento'
      message:
        $ref: '#/components/messages/EntityEvent'
    subscribe:
      summary: 'SuscripciÃ³n a eventos de {entity}'
      operationId: 'subscribeEntityEvent'
      bindings:
        kafka:
          groupId: 'entity-consumers'
          clientId: 'consumer-service'
      message:
        $ref: '#/components/messages/EntityEvent'

components:
  messages:
    EntityEvent:
      name: 'EntityEvent'
      title: 'Evento de Entidad'
      summary: 'Evento de cambio de estado de entidad'
      contentType: application/json
      headers:
        type: object
        properties:
          eventType:
            type: string
            enum: ['CREATED', 'UPDATED', 'DELETED']
          source:
            type: string
            description: 'Fuente del evento'
          timestamp:
            type: string
            format: date-time
      payload:
        $ref: '#/components/schemas/EntityEventPayload'
      examples:
        - name: 'entityCreated'
          summary: 'CreaciÃ³n de entidad'
          headers:
            eventType: 'CREATED'
            source: 'entity-service'
            timestamp: '2024-01-15T10:30:00Z'
          payload:
            entityId: 'uuid-here'
            status: 'ACTIVE'
            createdAt: '2024-01-15T10:30:00Z'

  schemas:
    EntityEventPayload:
      type: object
      required:
        - entityId
        - status
        - createdAt
      properties:
        entityId:
          type: string
          format: uuid
          description: 'Identificador Ãºnico de entidad'
        status:
          type: string
          enum: ['ACTIVE', 'INACTIVE', 'PENDING']
          description: 'Estado de la entidad'
        createdAt:
          type: string
          format: date-time
          description: 'Tiempo de creaciÃ³n del evento'
        metadata:
          type: object
          description: 'Datos adicionales'
          additionalProperties: true
      example:
        entityId: 'f47ac10b-58cc-4372-a567-0e02b2c3d479'
        status: 'ACTIVE'
        createdAt: '2024-01-15T10:30:00Z'
        metadata:
          source: 'web-app'
          userId: 'user-123'

  securitySchemes:
    saslScram:
      type: scramSha512
      description: 'AutenticaciÃ³n SASL/SCRAM'

  parameters:
    EntityId:
      description: 'Identificador de entidad'
      schema:
        type: string
        format: uuid

# ConfiguraciÃ³n adicional de Kafka (en secciÃ³n x-kafka-config)
x-kafka-config:
  cluster:
    brokers: 3
    replication:
      default: 2
      critical_topics: 3
    resources:
      broker_memory: '4Gi'
      broker_cpu: '2'
      broker_storage: '100Gi'
  
  producers:
    default_config:
      acks: 'all'
      retries: 10
      batch.size: 100000
      linger.ms: 5
      enable.idempotence: true
      compression.type: 'snappy'
    
  consumers:
    default_config:
      auto.commit.enable: false
      max.poll.records: 500
      session.timeout.ms: 30000
      fetch.min.bytes: 1
      
  monitoring:
    metrics:
      - 'kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec'
      - 'kafka.consumer:type=consumer-fetch-manager-metrics'
      - 'kafka.producer:type=producer-metrics'
    alerts:
      - name: 'high_consumer_lag'
        condition: 'consumer_lag > 10000'
        severity: 'critical'
      - name: 'broker_down'
        condition: 'broker_availability < 100%'
        severity: 'critical'
        
  security:
    authentication:
      protocol: 'SASL_SSL'
      mechanism: 'SCRAM-SHA-512'
    acls:
      - principal: 'User:entity-service'
        operations: ['Write', 'Describe']
        resources: ['Topic:domain.entity.events']
      - principal: 'User:consumer-service'
        operations: ['Read', 'Describe']
        resources: ['Topic:domain.entity.events', 'Group:entity-consumers']


##### 4.7.2.2. Reglas de nomenclatura de archivos:
- `{feature-name}_asyncapi.yaml` - para caracterÃ­sticas principales
- `{domain}_events_asyncapi.yaml` - para soluciones de dominio
- `{system-name}_kafka_asyncapi.yaml` - para integraciones de sistemas

**Ejemplos:**
- `banking_transfer_asyncapi.yaml`
- `ecommerce_orders_asyncapi.yaml`
- `notification_events_asyncapi.yaml`

##### 4.7.2.3. Secciones obligatorias de AsyncAPI:
1. **asyncapi**: versiÃ³n de especificaciÃ³n (2.6.0+)
2. **info**: metadatos de API
3. **servers**: configuraciÃ³n de clÃºster Kafka
4. **channels**: tÃ³picos y su configuraciÃ³n
5. **components**: esquemas de mensajes, esquemas de seguridad
6. **x-kafka-config**: configuraciÃ³n extendida de Kafka (opcional)

---

#### 4.7.3. Plantilla de descripciÃ³n de arquitectura Kafka

##### 4.7.3.1. Estructura obligatoria (9 bloques principales):

| â„– | Bloque | DescripciÃ³n | Obligatoriedad |
|---|------|----------|----------------|
| 1 | **DescripciÃ³n general** | PropÃ³sito de Kafka en el sistema, rol en arquitectura | âœ… Obligatorio |
| 2 | **TÃ³picos y esquemas** | Estructura de tÃ³picos, esquemas de mensajes, particionamiento | âœ… Obligatorio |
| 3 | **Productores** | Servicios emisores, estrategias de envÃ­o | âœ… Obligatorio |
| 4 | **Consumidores** | Servicios receptores, grupos de consumidores | âœ… Obligatorio |
| 5 | **ConfiguraciÃ³n de clÃºster** | Configuraciones de brokers, replicaciÃ³n, tolerancia a fallos | âœ… Obligatorio |
| 6 | **Esquemas de datos** | Esquemas Avro/JSON, Schema Registry, versionado | âœ… Obligatorio |
| 7 | **Seguridad** | AutenticaciÃ³n, autorizaciÃ³n, encriptaciÃ³n | ðŸ”¶ Recomendado |
| 8 | **Monitoreo y alertas** | MÃ©tricas, logging, SLA | ðŸ”¶ Recomendado |
| 9 | **Rendimiento** | Throughput, latencia, optimizaciones | ðŸ”¶ Recomendado |

---

#### 4.7.4. MÃ©tricas de calidad

##### 4.7.4.1. Indicadores objetivo:
- **Completitud estructural**: 6/6 bloques obligatorios = 100%
- **Cobertura de tÃ³picos**: DescripciÃ³n de todos los tÃ³picos principales del sistema
- **Esquemas de datos**: 100% tÃ³picos tienen descripciÃ³n de esquema
- **Grupos de consumidores**: SeparaciÃ³n clara de responsabilidades
- **Tolerancia a fallos**: MÃ­nimo 2x replicaciÃ³n para tÃ³picos crÃ­ticos

##### 4.7.4.2. Sistema de evaluaciÃ³n:
- **Listo para producciÃ³n**: 95-100% cumplimiento + seguridad + monitoreo
- **Calidad excelente**: 85-94% cumplimiento de mÃ©tricas
- **Buena calidad**: 70-84% cumplimiento de mÃ©tricas  
- **Requiere mejora**: <70% cumplimiento de mÃ©tricas

---

#### 4.7.5. Reglas de validaciÃ³n

##### 4.7.5.1. Comprobaciones automÃ¡ticas:

###### 4.7.5.1.1. ValidaciÃ³n estructural

âœ“ Los 6 bloques obligatorios presentes
âœ“ Cada tÃ³pico tiene descripciÃ³n de esquema
âœ“ Productores y consumidores claramente identificados
âœ“ Estrategia de particionamiento especificada


###### 4.7.5.1.2. ValidaciÃ³n arquitectÃ³nica

âœ“ TÃ³picos conectados lÃ³gicamente con dominios del sistema
âœ“ Esquemas de datos corresponden a especificaciones API
âœ“ Grupos de consumidores no se superponen en responsabilidad
âœ“ ReplicaciÃ³n configurada para tÃ³picos crÃ­ticos


###### 4.7.5.1.3. ValidaciÃ³n de producciÃ³n

âœ“ PolÃ­ticas de retenciÃ³n especificadas para todos los tÃ³picos
âœ“ Estrategia de manejo de errores descrita
âœ“ Monitoreo y alertas configurados
âœ“ Procedimientos de recuperaciÃ³n ante desastres documentados


---

#### 4.7.6. MetodologÃ­a de diseÃ±o

##### 4.7.6.1. Paso 1: AnÃ¡lisis de eventos de dominio
**Fuentes para anÃ¡lisis:**
- User Stories y Use Cases
- Diagramas de secuencia
- Diagrama de arquitectura del sistema
- Especificaciones API (para operaciones sÃ­ncronas)

##### 4.7.6.2. Paso 2: IdentificaciÃ³n de eventos
**Tipos de eventos:**
- **Eventos de Dominio**: cambios de estado de entidades de negocio
- **Eventos de IntegraciÃ³n**: comunicaciÃ³n entre servicios
- **Eventos de Sistema**: eventos tÃ©cnicos (logs, mÃ©tricas)
- **Eventos de Comando**: comandos asincrÃ³nicos

##### 4.7.6.3. Paso 3: DiseÃ±o de tÃ³picos
**Principios de nomenclatura:**

{domain}.{entity}.{event-type}
Ejemplos:
- banking.transfer.created
- banking.transfer.completed
- ecommerce.order.placed
- notification.email.sent


##### 4.7.6.4. Paso 4: DefiniciÃ³n de esquemas
**Formatos de esquemas:**
- **Avro**: tipado estricto, evoluciÃ³n de esquemas
- **JSON Schema**: flexibilidad, simplicidad
- **Protobuf**: rendimiento, compatibilidad

##### 4.7.6.5. Paso 5: PlanificaciÃ³n de particiones
**Estrategias de particionamiento:**
- Por ID de usuario (basado en usuario)
- Por ID de entidad (basado en entidad)
- Por marcas de tiempo (basado en tiempo)
- Round-robin (distribuciÃ³n uniforme)

##### 4.7.6.6. Paso 6: ConfiguraciÃ³n de consumidores
**Patrones de consumo:**
- **Consumidor Ãšnico**: procesamiento en orden
- **Grupo de Consumidores**: procesamiento paralelo
- **MÃºltiples Grupos**: lÃ³gica de negocio diferente

---

#### 4.7.7. Ejemplos de descripciÃ³n Kafka

##### 4.7.7.1. Ejemplo 1: Sistema de transferencias bancarias

###### 4.7.7.1.1. DescripciÃ³n general
**PropÃ³sito:** Procesamiento asincrÃ³nico de transferencias bancarias con garantÃ­as de entrega y auditorÃ­a de operaciones.
**Rol en arquitectura:** Bus de eventos central entre microservicios Banking, Notification, Audit, Fraud Detection.

###### 4.7.7.1.2. TÃ³picos y esquemas

**2.1. TÃ³pico: `banking.transfer.events`**
yaml
PropÃ³sito: Eventos del ciclo de vida de transferencias
Particiones: 12 (por account_id % 12)
Factor de ReplicaciÃ³n: 3
RetenciÃ³n: 30 dÃ­as
PolÃ­tica de Limpieza: delete


**Esquema de mensaje (Avro):**
json
{
  "type": "record",
  "name": "TransferEvent",
  "namespace": "com.bank.events",
  "fields": [
    {"name": "transferId", "type": "string"},
    {"name": "fromAccountId", "type": "string"},
    {"name": "toAccountId", "type": "string"},
    {"name": "amount", "type": {"type": "fixed", "name": "Decimal", "size": 16}},
    {"name": "currency", "type": "string"},
    {"name": "status", "type": {"type": "enum", "symbols": ["PENDING", "PROCESSING", "COMPLETED", "FAILED"]}},
    {"name": "timestamp", "type": {"type": "long", "logicalType": "timestamp-millis"}},
    {"name": "userId", "type": "string"},
    {"name": "comment", "type": ["null", "string"], "default": null}
  ]
}


**2.2. TÃ³pico: `banking.notifications.requests`**
yaml
PropÃ³sito: Solicitudes de envÃ­o de notificaciones
Particiones: 6 (por user_id % 6)
Factor de ReplicaciÃ³n: 2
RetenciÃ³n: 7 dÃ­as


**2.3. TÃ³pico: `banking.audit.log`**
yaml
PropÃ³sito: AuditorÃ­a de todas las operaciones para cumplimiento
Particiones: 1 (orden estricto)
Factor de ReplicaciÃ³n: 3
RetenciÃ³n: 7 aÃ±os (requisitos de cumplimiento)
PolÃ­tica de Limpieza: compact


###### 4.7.7.1.3. Productores

**3.1. Servicio de Transferencia (Productor principal)**
yaml
Servicio: transfer-service
TÃ³picos: banking.transfer.events
Estrategia: 
  - Idempotencia: habilitada
  - Acks: all (garantÃ­a de escritura en todas las rÃ©plicas)
  - Reintentos: 10
  - TamaÃ±o de Lote: 100KB
  - Tiempo de Espera: 5ms
Manejo de errores:
  - Reintento con exponential backoff
  - Cola de Mensajes Muertos: banking.transfer.dlq


**Ejemplo de cÃ³digo:**
java
@Service
public class TransferEventProducer {
    
    @Value("${kafka.topic.transfer-events}")
    private String transferEventsTopic;
    
    public void publishTransferEvent(TransferEvent event) {
        kafkaTemplate.send(transferEventsTopic, event.getFromAccountId(), event)
            .addCallback(
                result -> log.info("Event sent: {}", event.getTransferId()),
                failure -> log.error("Failed to send event", failure)
            );
    }
}


**3.2. Servicio de Notificaciones**
yaml
Servicio: notification-service  
TÃ³picos: banking.notifications.requests
Estrategia: Fire-and-forget (acks=1)


###### 4.7.7.1.4. Consumidores

**4.1. Servicio de DetecciÃ³n de Fraude**
yaml
Grupo: fraud-detection-group
TÃ³picos: banking.transfer.events
Estrategia:
  - Auto Commit: false (confirmaciÃ³n manual)
  - Registros MÃ¡ximos por Poll: 50
  - Tiempo de Espera de SesiÃ³n: 30s
  - AsignaciÃ³n de Particiones: cooperative-sticky
LÃ³gica:
  - AnÃ¡lisis de fraude
  - PublicaciÃ³n de resultado en fraud.detection.results


**4.2. Servicio de AuditorÃ­a**
yaml
Grupo: audit-group
TÃ³picos: 
  - banking.transfer.events
  - banking.notifications.requests
Estrategia:
  - Offset mÃ¡s temprano (procesamiento de todos los eventos)
  - Procesamiento por lotes (100 registros a la vez)
  - Procesamiento idempotente


**4.3. Consumidor de Notificaciones**
yaml
Grupo: notification-consumers
TÃ³picos: banking.notifications.requests
Paralelismo: 3 instancias
PolÃ­tica de Reintento:
  - Reintentos mÃ¡ximos: 5
  - Backoff: exponencial (1s, 2s, 4s, 8s, 16s)
  - DLQ: banking.notifications.dlq


###### 4.7.7.1.5. ConfiguraciÃ³n de clÃºster

**5.1. Brokers**
yaml
NÃºmero de brokers: 3
UbicaciÃ³n: 3 AZ diferentes
ConfiguraciÃ³n:
  - log.retention.hours: 168 (7 dÃ­as por defecto)
  - log.segment.bytes: 1GB
  - num.network.threads: 8
  - num.io.threads: 8
  - socket.send.buffer.bytes: 102400
  - socket.receive.buffer.bytes: 102400


**5.2. Zookeeper**
yaml
Nodos: 3 (quÃ³rum)
ConfiguraciÃ³n:
  - tickTime: 2000
  - initLimit: 10  
  - syncLimit: 5
  - maxClientCnxns: 60


**5.3. ReplicaciÃ³n**
yaml
TÃ³picos crÃ­ticos (transfers, audit): RF=3, min.insync.replicas=2
TÃ³picos regulares (notifications): RF=2, min.insync.replicas=1
TÃ³picos de prueba: RF=1


###### 4.7.7.1.6. Esquemas de datos

**6.1. Schema Registry**
yaml
URL: http://schema-registry:8081
Compatibilidad: BACKWARD
Versionado: automÃ¡tico
Subjects:
  - banking.transfer.events-value (v1, v2)
  - banking.notifications.requests-value (v1)
  - banking.audit.log-value (v1)


**6.2. EvoluciÃ³n de esquema**
json
// v1 -> v2: agregando campo metadata
{
  "type": "record",
  "name": "TransferEvent",
  "fields": [
    // ... campos existentes ...
    {"name": "metadata", "type": ["null", "string"], "default": null}
  ]
}


###### 4.7.7.1.7. Seguridad

**7.1. AutenticaciÃ³n**
yaml
Protocolo: SASL_SSL
Mecanismo: SCRAM-SHA-512
Usuarios:
  - transfer-service: acceso RW a banking.transfer.*
  - notification-service: acceso RW a banking.notifications.*
  - audit-service: acceso R a todos los tÃ³picos
  - fraud-detection: acceso R a banking.transfer.events


**7.2. AutorizaciÃ³n (ACL)**
bash
# Servicio de Transferencia
kafka-acls --add --allow-principal User:transfer-service \
  --operation Write --topic banking.transfer.events

# DetecciÃ³n de Fraude
kafka-acls --add --allow-principal User:fraud-detection \
  --operation Read --topic banking.transfer.events \
  --group fraud-detection-group


**7.3. EncriptaciÃ³n**
yaml
En trÃ¡nsito: TLS 1.3
En reposo: encriptaciÃ³n de disco LUKS
Schema Registry: mTLS + autenticaciÃ³n bÃ¡sica


###### 4.7.7.1.8. Monitoreo y alertas

**8.1. MÃ©tricas clave**
yaml
MÃ©tricas de Broker:
  - kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
  - kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec
  - kafka.server:type=ReplicaManager,name=LeaderCount

Lag de Consumidor:
  - kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*

MÃ©tricas de Productor:
  - kafka.producer:type=producer-metrics,client-id=*


**8.2. Alertas**
yaml
CrÃ­ticas:
  - Lag de Consumidor > 10000 mensajes
  - Broker no disponible > 1 minuto
  - Uso de disco > 85%

Advertencias:
  - Errores de Productor > 1%
  - Lag de ReplicaciÃ³n > 5 segundos
  - Rebalanceo de grupo de consumidores


**8.3. Dashboards**
yaml
Paneles de Grafana:
  - Vista General del ClÃºster Kafka
  - Rendimiento de TÃ³picos
  - Estado de Grupos de Consumidores
  - Rendimiento de Productores
  - Tasas de Error


###### 4.7.7.1.9. Rendimiento

**9.1. CaracterÃ­sticas de throughput**
yaml
Indicadores objetivo:
  - Transferencias: 10,000 msg/seg
  - Notificaciones: 5,000 msg/seg
  - AuditorÃ­a: 15,000 msg/seg

Latencia (p99):
  - Productor: < 50ms
  - Consumidor: < 100ms
  - Extremo a extremo: < 200ms


**9.2. Optimizaciones**
yaml
Productor:
  - TamaÃ±o de lote: 100KB
  - Tiempo de espera: 5ms
  - CompresiÃ³n: snappy

Consumidor:
  - TamaÃ±o de fetch: 1MB
  - Registros mÃ¡ximos por poll: 500
  - Procesamiento paralelo

Broker:
  - Segmento de log: 1GB
  - Flush de log: asÃ­ncrono
  - Cache de pÃ¡gina: 70% RAM


---

##### 4.7.7.2. Ejemplo 2: Plataforma E-commerce

###### 4.7.7.2.1. DescripciÃ³n general
**PropÃ³sito:** Arquitectura dirigida por eventos para e-commerce con procesamiento de pedidos, inventario y notificaciones.
**Rol en arquitectura:** Bus de eventos principal entre Order Service, Inventory Service, Payment Service, Notification Service.

###### 4.7.7.2.2. TÃ³picos y esquemas

**2.1. TÃ³pico: `ecommerce.orders.events`**
yaml
PropÃ³sito: Eventos del ciclo de vida de pedidos
Particiones: 8 (por hash de order_id)
Factor de ReplicaciÃ³n: 2
RetenciÃ³n: 14 dÃ­as


**Esquema (JSON Schema):**
json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "type": "object",
  "properties": {
    "orderId": {"type": "string", "format": "uuid"},
    "customerId": {"type": "string", "format": "uuid"},
    "status": {"enum": ["PLACED", "CONFIRMED", "SHIPPED", "DELIVERED", "CANCELLED"]},
    "items": {
      "type": "array",
      "items": {
        "type": "object",
        "properties": {
          "productId": {"type": "string"},
          "quantity": {"type": "integer", "minimum": 1},
          "price": {"type": "number", "minimum": 0}
        }
      }
    },
    "totalAmount": {"type": "number", "minimum": 0},
    "timestamp": {"type": "string", "format": "date-time"}
  },
  "required": ["orderId", "customerId", "status", "items", "totalAmount", "timestamp"]
}


**2.2. TÃ³pico: `ecommerce.inventory.updates`**
yaml
PropÃ³sito: Actualizaciones de stock de productos
Particiones: 4 (por hash de product_id)
Factor de ReplicaciÃ³n: 2
RetenciÃ³n: 7 dÃ­as
PolÃ­tica de Limpieza: compact (estado mÃ¡s reciente)


**2.3. TÃ³pico: `ecommerce.payments.events`**
yaml
PropÃ³sito: Eventos de pagos
Particiones: 6
Factor de ReplicaciÃ³n: 3 (datos crÃ­ticos)
RetenciÃ³n: 365 dÃ­as (cumplimiento)


###### 4.7.7.2.3. Productores

**3.1. Order Service**
yaml
TÃ³picos: ecommerce.orders.events
ConfiguraciÃ³n:
  - acks: all
  - enable.idempotence: true
  - retries: Integer.MAX_VALUE
  - max.in.flight.requests.per.connection: 5

PatrÃ³n Outbox:
  - Escritura transaccional en BD + Kafka
  - GarantÃ­as de consistencia eventual


**3.2. Inventory Service**
yaml
TÃ³picos: ecommerce.inventory.updates
Estrategia: TÃ³pico compactado para estado actual


###### 4.7.7.2.4. Consumidores

**4.1. Payment Service**
yaml
Grupo: payment-processors
TÃ³picos: ecommerce.orders.events
Filtro: status = "PLACED"
LÃ³gica: IniciaciÃ³n de pago
Resultado: PublicaciÃ³n en ecommerce.payments.events


**4.2. Inventory Service**  
yaml
Grupo: inventory-updaters
TÃ³picos: ecommerce.orders.events
LÃ³gica: Reserva/liberaciÃ³n de productos
Idempotencia: Por order_id + item_id


**4.3. Notification Service**
yaml
Grupo: notification-senders
TÃ³picos: 
  - ecommerce.orders.events
  - ecommerce.payments.events
Paralelismo: 5 consumidores
Reintento: 3 intentos con backoff


###### 4.7.7.2.5. ConfiguraciÃ³n de clÃºster

**5.1. Despliegue**
yaml
Entorno: Kubernetes
Brokers: 3 pods
Recursos:
  - CPU: 2 nÃºcleos
  - Memoria: 4GB
  - Almacenamiento: 100GB SSD por broker


**5.2. Configuraciones de rendimiento**
yaml
log.retention.bytes: 10GB por particiÃ³n
log.segment.bytes: 512MB
compression.type: snappy
num.replica.fetchers: 4


###### 4.7.7.2.6. Monitoreo

**6.1. MÃ©tricas de negocio**
yaml
- Pedidos procesados por minuto
- Tasa de Ã©xito de pagos
- Retraso de sincronizaciÃ³n de inventario
- Tasa de entrega de notificaciones a clientes


**6.2. MÃ©tricas tÃ©cnicas**
yaml
- Lag de consumidor por tÃ³pico
- Throughput de productor
- Tasas de error por servicio
- DistribuciÃ³n de particiones


---

#### 4.7.8. Criterios de calidad para IA

##### 4.7.8.1. Madurez arquitectÃ³nica
- **Obligatorio**: Todos los 6 bloques principales completados
- **ProducciÃ³n**: Bloques de seguridad, monitoreo, rendimiento agregados
- **Empresa**: RecuperaciÃ³n ante desastres, cumplimiento, gobierno agregados

##### 4.7.8.2. Detallado tÃ©cnico
- **TÃ³picos**: Esquema de particionamiento claro y polÃ­ticas de retenciÃ³n
- **Esquemas**: Esquemas Avro/JSON vÃ¡lidos con ejemplos
- **ConfiguraciÃ³n**: Configuraciones realistas para carga objetivo
- **Seguridad**: ACL, autenticaciÃ³n, encriptaciÃ³n

##### 4.7.8.3. PreparaciÃ³n operacional
- **Monitoreo**: MÃ©tricas clave y alertas definidas
- **Manejo de errores**: DLQ, polÃ­ticas de reintento, circuit breakers
- **Rendimiento**: SLA, requisitos de throughput y latencia
- **RecuperaciÃ³n ante Desastres**: Procedimientos de backup, restore, failover

##### 4.7.8.4. IntegraciÃ³n con sistema
- **Eventos de Dominio**: Corresponden con lÃ³gica de negocio de Use Cases
- **IntegraciÃ³n API**: Complementan arquitectura REST API
- **Flujo de Datos**: Consistentes con diagramas de secuencia
- **Servicios**: Corresponden con arquitectura de componentes

---

#### 4.7.9. Lista de verificaciÃ³n para agente IA

##### 4.7.9.1. VerificaciÃ³n obligatoria:
- [ ] âœ… Archivo YAML AsyncAPI creado con nombre correcto
- [ ] âœ… VersiÃ³n AsyncAPI especificada (2.6.0+)
- [ ] âœ… SecciÃ³n info completamente completada
- [ ] âœ… Servers contiene configuraciÃ³n Kafka
- [ ] âœ… Channels describe todos los tÃ³picos
- [ ] âœ… Cada channel tiene operaciones publish/subscribe
- [ ] âœ… Components contiene esquemas de mensajes
- [ ] âœ… Estrategia de particionamiento definida en bindings
- [ ] âœ… ReplicaciÃ³n configurada en kafka bindings
- [ ] âœ… PolÃ­ticas de retenciÃ³n descritas en configs
- [ ] âœ… Esquemas de datos vÃ¡lidos (JSON Schema)
- [ ] âœ… Grupos de consumidores especificados en bindings
- [ ] âœ… Sintaxis YAML AsyncAPI correcta

##### 4.7.9.2. VerificaciÃ³n de calidad:
- [ ] ðŸŽ¯ TÃ³picos conectados lÃ³gicamente con dominios
- [ ] ðŸŽ¯ Esquemas soportan evoluciÃ³n (compatibilidad hacia atrÃ¡s)
- [ ] ðŸŽ¯ Manejo de errores mediante DLQ descrito
- [ ] ðŸŽ¯ Procesamiento idempotente asegurado
- [ ] ðŸŽ¯ Acuses de recibo de productor configurados correctamente
- [ ] ðŸŽ¯ GestiÃ³n de offset de consumidor definida

##### 4.7.9.3. VerificaciÃ³n listo para producciÃ³n:
- [ ] ðŸš€ Seguridad: SASL/SSL, ACL configurados
- [ ] ðŸš€ Monitoreo: mÃ©tricas y alertas definidas
- [ ] ðŸš€ Rendimiento: SLA y optimizaciones descritas
- [ ] ðŸš€ Procedimientos de backup y recuperaciÃ³n ante desastres
- [ ] ðŸš€ Schema Registry configurado
- [ ] ðŸš€ Monitoreo de lag de consumidor
- [ ] ðŸš€ Procesamiento de Dead Letter Queue
- [ ] ðŸš€ PlanificaciÃ³n de capacidad (particiones, brokers)

##### 4.7.9.4. VerificaciÃ³n de integraciÃ³n:
- [ ] ðŸ”— Eventos corresponden con Use Cases
- [ ] ðŸ”— Esquemas compatibles con especificaciones API
- [ ] ðŸ”— Servicios productores existen en diagrama de arquitectura
- [ ] ðŸ”— Grupos de consumidores no conflictivos en responsabilidad
- [ ] ðŸ”— CaracterÃ­sticas de tiempo realistas
- [ ] ðŸ”— VolÃºmenes de datos corresponden con escala del sistema

**Objetivo**: Crear archivos YAML con descripciÃ³n de arquitectura Kafka, listos para despliegue en producciÃ³n con cobertura completa de requisitos funcionales y no funcionales.

##### 4.7.9.5. VerificaciÃ³n final YAML AsyncAPI:
- [ ] ðŸ“„ Archivo guardado con extensiÃ³n .yaml
- [ ] ðŸ“„ Nombre de archivo sigue convenciÃ³n de nomenclatura
- [ ] ðŸ“„ Estructura AsyncAPI corresponde a especificaciÃ³n
- [ ] ðŸ“„ Todos los valores de cadena entre comillas
- [ ] ðŸ“„ IndentaciÃ³n realizada con espacios (no tabs)
- [ ] ðŸ“„ JSON Schema correctamente definidos en components
- [ ] ðŸ“„ Kafka bindings configurados para channels
- [ ] ðŸ“„ Esquemas de seguridad definidos cuando sea necesario
- [ ] ðŸ“„ Ejemplos incluidos para cada tipo de mensaje

---

#### 4.7.10. Recomendaciones adicionales

##### 4.7.10.1. Estilo de documentaciÃ³n:
- **Estructura**: Use YAML para configuraciones
- **Especificidad**: Especifique nÃºmeros exactos de particiones, retenciÃ³n, throughput
- **Ejemplos**: Incluya ejemplos reales de esquemas Avro/JSON Schema
- **VisualizaciÃ³n**: Diagramas ASCII para topologÃ­a

##### 4.7.10.2. Aspectos de producciÃ³n:
- **Nomenclatura**: Siga convenciones {domain}.{entity}.{event}
- **Particionamiento**: Justifique elecciÃ³n de clave de particionamiento
- **RetenciÃ³n**: Considere cumplimiento y costos de almacenamiento
- **Versionado**: Planifique evoluciÃ³n de esquemas por adelantado

##### 4.7.10.3. IntegraciÃ³n con DevOps:
- **Infraestructura como CÃ³digo**: Configuraciones Terraform/Helm
- **CI/CD**: ValidaciÃ³n de esquemas en pipeline
- **Monitoreo**: MÃ©tricas Prometheus/Grafana
- **Alertas**: Integraciones PagerDuty/Slack

##### 4.7.10.4. RecuperaciÃ³n ante Desastres:
- **Backup**: MirrorMaker 2.0 para replicaciÃ³n
- **RecuperaciÃ³n**: Requisitos RTO/RPO
- **Pruebas**: PrÃ¡cticas de ingenierÃ­a del caos
- **DocumentaciÃ³n**: Runbooks para equipo de operaciones


